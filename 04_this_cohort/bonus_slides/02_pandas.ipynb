{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "40d3f376",
      "metadata": {
        "id": "40d3f376"
      },
      "source": [
        "# Doing More with Data: `pandas`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d59f3e1e",
      "metadata": {
        "id": "d59f3e1e"
      },
      "source": [
        "# Contents:\n",
        "\n",
        "1. Setup\n",
        "2. Intro to `pandas`\n",
        "2. Getting data\n",
        "3. Profiling and initial data exploration: changing data types, descriptive statistics\n",
        "4. Wrangling and plotting: concatenating, merging, adding and removing columns, filtering and selecting, null values, grouping and aggregating, plotting\n",
        "5. Writing to file\n",
        "6. More wrangling: reshaping, applying functions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "617bcc6b",
      "metadata": {
        "id": "617bcc6b"
      },
      "source": [
        "## Data\n",
        "\n",
        "This module uses four datasets: [bike thefts](https://open.toronto.ca/dataset/bicycle-thefts/), [TTC subway delays and subway delay reason codes](https://open.toronto.ca/dataset/ttc-subway-delay-data/), and [neighbourhood profiles](https://open.toronto.ca/dataset/neighbourhood-profiles/). All four are available in the course repo, and originally come from Toronto Open Data.\n",
        "\n",
        "The specific file names are:\n",
        "- bicycle-thefts - 4326.csv\n",
        "- ttc-subway-delay-data-2021.xlsx\n",
        "- ttc-subway-delay-codes.xlsx\n",
        "- neighbourhood-profiles-2016-140-model.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b80d4fb6",
      "metadata": {
        "id": "b80d4fb6"
      },
      "source": [
        "# `pandas`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4339b9f2",
      "metadata": {
        "id": "4339b9f2"
      },
      "source": [
        "## What is `pandas`?\n",
        "\n",
        "`pandas` is a package for data analysis and manipulation. (The name is a reference to panel data, not the animal.) It gives us data frames, which represent data in a table of columns and rows, and functions to manipulate and plot them. `pandas` also provides a slew of functions for reading and writing data to a variety of sources, including files, SQL databases, and compressed binary formats."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "516e431e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# If there are issues with library installation please type the following commands into Terminal:\n",
        "\n",
        "# conda install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cea5f938",
      "metadata": {
        "id": "cea5f938"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# pd is the conventional alias for pandas\n",
        "import pandas as pd\n",
        "\n",
        "# display all columns\n",
        "pd.set_option(\"display.max_columns\", None)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4891c551",
      "metadata": {
        "id": "4891c551"
      },
      "source": [
        "## DataFrames\n",
        "\n",
        "Columns are labeled with their names. Rows also have a label, or _index_. If row labels are not specified, `pandas` uses numbers as the default. Each column is a _Series_, or one-dimensional array, where values share a data type. Unlike `numpy` arrays, DataFrames can have columns of different data types. However, like arrays and lists, **DataFrames are mutable** -- this means that if more than one variable refers to the same DataFrame, updating one updates them all!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6536654d",
      "metadata": {
        "id": "6536654d"
      },
      "source": [
        "## Getting data\n",
        "\n",
        "We can create a DataFrame manually with `DataFrame()` constructor. If a dictionary is passed to `DataFrame()`, the keys become column names, and the values become the rows. Calling just `DataFrame()` creates an empty DataFrame to which data can be added later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d035bb4a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "d035bb4a",
        "outputId": "dca96c28-14db-4ede-803e-55279f475464"
      },
      "outputs": [],
      "source": [
        "trees = pd.DataFrame({\n",
        "    'name': ['sugar maple', 'black oak', 'white ash', 'douglas fir'],\n",
        "    'avg_lifespan': [300, 100, 260, 450],\n",
        "    'quantity': [53, 207, 178, 93]\n",
        "})\n",
        "trees"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdc4ca75",
      "metadata": {
        "id": "fdc4ca75"
      },
      "source": [
        "We can create an individual column with `Series()`. The `name` argument corresponds to a column name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99aa5f2b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99aa5f2b",
        "outputId": "36bc2a39-57fb-4618-ea71-3622ab333108"
      },
      "outputs": [],
      "source": [
        "tree_types = pd.Series(['deciduous', 'deciduous', 'deciduous', 'evergreen'],\n",
        "                       name='foliage')\n",
        "tree_types"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b611794",
      "metadata": {
        "id": "4b611794"
      },
      "source": [
        "### Data from csv\n",
        "\n",
        "Of course, we're more likely to load data into a DataFrame than to create DataFrames manually. `pandas` has read functions for different file formats. To read data from a csv or other delimited file, we use `pd.read_csv()`, then pass in the local file path or the URL of the csv to read. `pandas` will infer the data type of each column based on the values in the first chunk of the file loaded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3473e899",
      "metadata": {
        "id": "3473e899"
      },
      "outputs": [],
      "source": [
        "thefts = pd.read_csv('../../05_src/data/slides_data/bicycle_thefts_4326.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24d22043",
      "metadata": {
        "id": "24d22043"
      },
      "source": [
        "## Profiling and initial data cleaning\n",
        "\n",
        "We got our data, but now we need to understand what's in it. We can start to understand the DataFrame by checking out its `dtypes` and `shape` attributes, which give column data types and row by column dimensions, respectively. Note that `object` is `pandas`' way of saying values are represented as string data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b4bbb4c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b4bbb4c",
        "outputId": "68c1c782-fcda-4956-f9d7-600a018e6659"
      },
      "outputs": [],
      "source": [
        "thefts.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21852697",
      "metadata": {},
      "source": [
        "The `object` dtype in a pandas DataFrame represents columns that contain text or mixed types of data. When you use the `.dtypes` method on a pandas DataFrame and see that a column is listed as having the `object` dtype, it typically means that the data within that column is stored as strings (there isn't a dedicated `str` dtype for columns). However, `object` dtype columns can also hold data that is a mix of different types, including numbers, strings, or even more complex objects like lists or dictionaries, if the data within the column is not homogenous.\n",
        "\n",
        "The `object` dtype is essentially a catch-all for columns that don't fit neatly into more specific types like `int64`, `float64`, `datetime64`, etc. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92ccbe1a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92ccbe1a",
        "outputId": "67338dd9-95dd-40a1-fe80-0af988bdf892"
      },
      "outputs": [],
      "source": [
        "thefts.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f1bfa33",
      "metadata": {
        "id": "6f1bfa33"
      },
      "source": [
        "### `head()`s and `tail()`s\n",
        "\n",
        "To check out the first few rows, we can call the DataFrame `head()` method. Similarly, we can see the last few rows with the `tail()` method. Five rows are shown by default, but we can change that by passing an integer as an argument."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f2217f1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "9f2217f1",
        "outputId": "eca7e551-d812-446e-98cb-f4da50106f21",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "thefts.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41b2e05c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "41b2e05c",
        "outputId": "614a8063-fb46-4bdb-8a68-ff1e3cac25b5"
      },
      "outputs": [],
      "source": [
        "# last 3\n",
        "thefts.tail(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ffd0b4b",
      "metadata": {
        "id": "2ffd0b4b"
      },
      "source": [
        "### Renaming columns\n",
        "\n",
        "Most, but not all, of the bike theft columns follow the same naming convention. For convenience's sake, though, let's convert the column names to all lowercase. We can do this with the DataFrame `rename()` method. `rename()` accepts either a dictionary with current column names as the keys and new names as the values, or the name of a function to transform names. Let's write a function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ae1134b",
      "metadata": {
        "id": "7ae1134b"
      },
      "outputs": [],
      "source": [
        "# notice that we do not add () to the function name\n",
        "thefts = thefts.rename(columns=str.lower)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HamR_aJPTuwb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 915
        },
        "id": "HamR_aJPTuwb",
        "outputId": "04b7f55f-71bb-499d-dcb4-6896b63ada5d"
      },
      "outputs": [],
      "source": [
        "thefts"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae4bdd8a",
      "metadata": {
        "id": "ae4bdd8a"
      },
      "source": [
        "Let's also rename `cost_of_bike` so it follows the pattern of the other bike attribute columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f221dbc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f221dbc",
        "outputId": "a3db8195-3a9f-404b-dae6-88c7031f4649"
      },
      "outputs": [],
      "source": [
        "thefts = thefts.rename(columns={'cost_of_bike':'bike_cost'})\n",
        "\n",
        "# view column names\n",
        "# when you wrap a DataFrame object with the list() function, Python converts the DataFrame's column headers into a list\n",
        "print(list(thefts))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cf14e92",
      "metadata": {
        "id": "8cf14e92"
      },
      "source": [
        "### Profiling columns\n",
        "\n",
        "It can be useful to focus on a subset of columns, particularly to understand value sets. To select a single column in a DataFrame, we can supply the name of the column in square brackets, just like we did when accessing values in a dictionary. `pandas` will return the column as a Series. To get unique values, we can use the `unique()` Series method. If we want to count how many times each value appears, we can use the `value_counts()` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bab6f2f7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bab6f2f7",
        "outputId": "199637e2-23b4-4cb5-ff7b-43d3a06a5a87"
      },
      "outputs": [],
      "source": [
        "thefts['status']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1babac10",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1babac10",
        "outputId": "1a90bcc2-cfa6-43bd-ec8e-cb307ad45934"
      },
      "outputs": [],
      "source": [
        "thefts['status'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26976b4b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26976b4b",
        "outputId": "d749ee7d-b61a-4d82-9f2a-e4872da8d932"
      },
      "outputs": [],
      "source": [
        "thefts['status'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49505d9c",
      "metadata": {
        "id": "49505d9c"
      },
      "source": [
        "We can summarize numeric Series much like we did with `numpy` functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01d6bffa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01d6bffa",
        "outputId": "5096f01b-69f7-46c5-904f-c293a786ede8"
      },
      "outputs": [],
      "source": [
        "thefts['bike_cost'].median()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a7f4104",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a7f4104",
        "outputId": "d0d29f57-cdae-4d12-df7c-1765babd8474"
      },
      "outputs": [],
      "source": [
        "thefts['bike_cost'].quantile(0.9) #qth quantile"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d34d6368",
      "metadata": {
        "id": "d34d6368"
      },
      "source": [
        "### `info()`\n",
        "\n",
        "We can get an overview of the DataFrame by profiling it with the `info()` method.\n",
        "\n",
        "`info()` prints a lot of information about a DataFrame, including:\n",
        "* the `shape` as the number of rows and columns\n",
        "* column names and their `dtype`\n",
        "* the number of non-null values in each column\n",
        "* how big the DataFrame is in terms of memory usage"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "815e6e4b",
      "metadata": {
        "id": "815e6e4b"
      },
      "source": [
        "The bicycle theft data looks quite complete, though some records are missing bike descriptors like bike_make, bike_model, bike_colour, and bike_cost.\n",
        "\n",
        "Most of the column dtypes make sense. We'll want to convert the dates to proper dates. We may also want to convert string columns with limited value sets, like status, to categorical data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0ff7d64",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0ff7d64",
        "outputId": "5d8d883a-6c58-4f89-f96c-64268bb282e2",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "thefts.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5533a5de",
      "metadata": {
        "id": "5533a5de"
      },
      "source": [
        "### Changing data types\n",
        "\n",
        "Before exploring the bike theft data further, let's fix the date and categorical columns. To convert a column to datetime, we use the `pd.to_datetime()` function, passing in the column to convert, and reassign the output back to the column we're converting.\n",
        "\n",
        "`pandas` knows how to convert the dates in the bike thefts data, but for less common formats, it is necessary to use the `format` keyword argument to specify how dates should be parsed. `format` strings use `strftime` codes. See https://strftime.org/ for a cheat sheet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a42f4c89",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a42f4c89",
        "outputId": "9b55ef22-c600-46c2-c08f-7432a4a12ead"
      },
      "outputs": [],
      "source": [
        "thefts['occurrence_date'] = pd.to_datetime(thefts['occurrence_date'])\n",
        "thefts['occurrence_date']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4722100d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4722100d",
        "outputId": "e1791410-324e-4a47-903d-e39ccdb36acf"
      },
      "outputs": [],
      "source": [
        "# convert report_date without the format argument\n",
        "thefts['report_date'] = pd.to_datetime(thefts['report_date'])\n",
        "thefts['report_date']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df68b74d",
      "metadata": {
        "id": "df68b74d"
      },
      "source": [
        "All other data type conversions can be done with the `astype()` method. If we were converting to a number, `pd.to_numeric()` provides an easy way to convert without having to pick a specific numeric data type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5adc64a3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5adc64a3",
        "outputId": "167a698c-ebd0-45bb-80c7-df5417ef5749"
      },
      "outputs": [],
      "source": [
        "# 'category' data type represents a variable that can take on a limited, fixed number of possible values\n",
        "# useful for representing data that can be separated into distinct groups based on certain characteristics\n",
        "# but doesn't necessarily have a mathematical order or numerical relationship between them\n",
        "\n",
        "thefts['status'] = thefts['status'].astype('category')\n",
        "thefts['status']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c574958",
      "metadata": {
        "id": "2c574958"
      },
      "source": [
        "We can select and convert multiple columns at once by passing a list of columns in the square brackets., then using `.astype()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c327ef8b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c327ef8b",
        "outputId": "0c4c220a-605b-4555-c198-fe32d6eb4633"
      },
      "outputs": [],
      "source": [
        "thefts[['location_type', 'premises_type']] = thefts[['location_type','premises_type']].astype('category')\n",
        "\n",
        "# check data types\n",
        "thefts[['location_type', 'premises_type']].dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d9c4a20",
      "metadata": {
        "id": "4d9c4a20"
      },
      "source": [
        "### `describe()`\n",
        "\n",
        "To get a sense of the values in a DataFrame, we can use the `describe()` method. `describe()` summarizes only numeric columns by default. Passing the `include='all'` argument will produce summary statistics for other columns as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8115ab9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "c8115ab9",
        "outputId": "86ceb7bb-def7-4ede-a4c1-3de7cfd28e88"
      },
      "outputs": [],
      "source": [
        "thefts.describe(include='all') "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98f401a5",
      "metadata": {
        "id": "98f401a5"
      },
      "source": [
        "## Wrangling and Plotting"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "076d08b1",
      "metadata": {
        "id": "076d08b1"
      },
      "source": [
        "### Combining datasets: concatenation\n",
        "\n",
        "Just as `pandas` has `read_csv()` for flat files, there is a `read_excel()` function to load Excel files.\n",
        "\n",
        "The TTC publishes subway delay data as a multi-sheet Excel workbook, with a month's worth of data per sheet. `read_excel()` loads just the first sheet in an Excel file by default. To load all sheets, pass in the keyword argument `sheet_name=None`. The result is a dictionary, where each key is the sheet name and each value is a DataFrame with the contents of the sheet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf844e1a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# If there are issues with library installation please type the following commands into Terminal:\n",
        "# conda install openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ce56e2e",
      "metadata": {
        "id": "0ce56e2e"
      },
      "outputs": [],
      "source": [
        "delays = pd.read_excel('../../05_src/data/slides_data/ttc_subway_delay_data_2021.xlsx', sheet_name=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "256c6e97",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "256c6e97",
        "outputId": "00815cab-bb06-4692-b012-d8e622351717"
      },
      "outputs": [],
      "source": [
        "type(delays)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f757ac4",
      "metadata": {
        "id": "4f757ac4"
      },
      "source": [
        "To combine them all, we create an empty DataFrame, then loop through the dictionary items and use `pd.concat()` to append data. `concat()` takes a list of DataFrames to combine. Since we did not specify an index, row labels are numbers: the first row of each sheet has an index of 0, and so on. To reset row labels so that they are sequential again, we set `ignore_index=True`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81bd009e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81bd009e",
        "outputId": "3783f307-5aad-4d42-b8ec-c35d02224467"
      },
      "outputs": [],
      "source": [
        "# create an empty DataFrame\n",
        "all_delays = pd.DataFrame()\n",
        "\n",
        "for sheet_name, values in delays.items():\n",
        "    # print the number of rows\n",
        "    print(f'Adding {values.shape[0]} rows from {sheet_name}')\n",
        "    # add each sheet to all_delays\n",
        "    all_delays = pd.concat([all_delays, values],\n",
        "                           axis=0,  # concatenate rows\n",
        "                           ignore_index=True)  # reset row labels\n",
        "\n",
        "all_delays.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b407508c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "b407508c",
        "outputId": "4a4c9d43-6ff4-4c45-9fe5-2836b26ce952"
      },
      "outputs": [],
      "source": [
        "all_delays.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5889dc0a",
      "metadata": {
        "id": "5889dc0a"
      },
      "source": [
        "The TTC delays data includes a reason code for the delay. Code definitions, however, are in a separate Excel file, `ttc-subway-delay-codes.xlsx`. This file has been modified slightly to make it easier to work with. Codes are split between two tabs, so we will load both to a DataFrame, `delay_reasons`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53e525c3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "53e525c3",
        "outputId": "fd6d3160-5b03-41b8-c93d-34da9090a4e5"
      },
      "outputs": [],
      "source": [
        "dr = pd.read_excel('../../05_src/data/slides_data/ttc_subway_delay_codes.xlsx', sheet_name=None)\n",
        "\n",
        "delay_reasons = pd.DataFrame()\n",
        "for sheet_name, values in dr.items():\n",
        "    delay_reasons = pd.concat([delay_reasons, values],\n",
        "                             axis=0,\n",
        "                             ignore_index=True)\n",
        "\n",
        "delay_reasons"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fEIT90L-HPny",
      "metadata": {
        "id": "fEIT90L-HPny"
      },
      "source": [
        "We will rename the columns in both `all_delays` and `delay_reasons` so that we replace spaces with underscores as well as convert all letters to lowercase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7c6fd96",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7c6fd96",
        "outputId": "43ea8951-5688-4107-b35d-a677fcc0d0fa"
      },
      "outputs": [],
      "source": [
        "def clean_names(string):\n",
        "    return string.lower().replace(' ', '_')\n",
        "\n",
        "print(list(delay_reasons))\n",
        "print(list(all_delays))\n",
        "delay_reasons = delay_reasons.rename(columns=clean_names)\n",
        "all_delays = all_delays.rename(columns=clean_names)\n",
        "print(list(delay_reasons))\n",
        "print(list(all_delays))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2b1b5f4",
      "metadata": {
        "id": "c2b1b5f4"
      },
      "source": [
        "## Combining datasets: merging\n",
        "\n",
        "Ideally, the delays data would include code descriptions. We can get descriptions into `all_delays` by _merging_ in `delay_reasons`. Merging is analagous to joining in SQL databases. To merge two DataFrames, we pass them as arguments to the `pd.merge()`. Then, we specify `how` to merge the two DataFrames and what column names to merge `on`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32f9f2b2",
      "metadata": {
        "id": "32f9f2b2"
      },
      "source": [
        "Let's review the `all_delays` and `delay_reasons` DataFrames. `code` is equivalent to `rmenu_code`. If we pass in `all_delays` as the first DataFrame, then it will be the left frame, and `delay_reasons` the right one. We want to keep all the delay records, even if there isn't a matching code in `delay_reasons`, so we will perform a left join."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fd6c216",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "0fd6c216",
        "outputId": "3e124116-82da-4a9b-ef08-9e18bd9f46e6"
      },
      "outputs": [],
      "source": [
        "all_delays.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fbb4203",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "8fbb4203",
        "outputId": "f1e44d73-124b-452a-ae5d-15b3df08e435"
      },
      "outputs": [],
      "source": [
        "delay_reasons.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6f6b219",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "b6f6b219",
        "outputId": "a4f160a6-3b9b-4ae5-a3dc-ddf1ce908903"
      },
      "outputs": [],
      "source": [
        "delays_w_reasons = pd.merge(all_delays,\n",
        "                            delay_reasons,\n",
        "                            how='left',\n",
        "                            left_on='code',\n",
        "                            right_on='rmenu_code')\n",
        "delays_w_reasons.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "600b645e",
      "metadata": {
        "id": "600b645e"
      },
      "source": [
        "## `drop()`\n",
        "\n",
        "The resulting DataFrame has both our join columns, which is redundant. We can drop one with the `drop()` DataFrame method, passing in the column name(s) we want to drop in the `columns` keyword argument."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ad1af1d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "3ad1af1d",
        "outputId": "6e74809a-d521-40f9-9199-409b056e5281"
      },
      "outputs": [],
      "source": [
        "delays_w_reasons = delays_w_reasons.drop(columns='rmenu_code')\n",
        "delays_w_reasons.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3f80a0d",
      "metadata": {
        "id": "f3f80a0d"
      },
      "source": [
        "## Creating new columns\n",
        "\n",
        "Adding a column to a DataFrame looks like adding a key-value pair to a dictionary. At its simplest, we can assign a single value to repeat down a column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96c7d550",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96c7d550",
        "outputId": "5ff71183-ddd7-482a-b744-6b46d5529972"
      },
      "outputs": [],
      "source": [
        "delays_w_reasons['year'] = 2021\n",
        "delays_w_reasons['year'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2ciLvPNkqHP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "b2ciLvPNkqHP",
        "outputId": "12447b0a-89f4-40e7-fa38-183e427579cd"
      },
      "outputs": [],
      "source": [
        "delays_w_reasons"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4472b1c3",
      "metadata": {
        "id": "4472b1c3"
      },
      "source": [
        "We can also write an expression and store the resulting values in a new column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67d1a11a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "67d1a11a",
        "outputId": "c99c884e-6de5-4cda-a9d1-66732ba11cd3"
      },
      "outputs": [],
      "source": [
        "delays_w_reasons['hour_delay'] = round(delays_w_reasons['min_delay'] / 60, 2)\n",
        "delays_w_reasons[['min_delay', 'hour_delay']].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca901417",
      "metadata": {
        "id": "ca901417"
      },
      "source": [
        "It is also possible to extract parts of a datetime column with the `dt` accessor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2X2cf70PWkzM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2X2cf70PWkzM",
        "outputId": "120c31f5-a7f3-449d-eaae-d560ecf0d06c"
      },
      "outputs": [],
      "source": [
        "delays_w_reasons.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7bf8880",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7bf8880",
        "outputId": "cbdc0e81-f1b7-4ae6-c5dc-5c6e86732a28"
      },
      "outputs": [],
      "source": [
        "delays_w_reasons['month'] = delays_w_reasons['date'].dt.month\n",
        "delays_w_reasons['month']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "529e579d",
      "metadata": {
        "id": "529e579d"
      },
      "source": [
        "It is possible to create a new integer column, `hour`, that contains the hour in which a delay occurred. Below we highlight two methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5fd6616",
      "metadata": {
        "id": "f5fd6616"
      },
      "outputs": [],
      "source": [
        "# two ways to extract hour\n",
        "# convert to time, then access hour\n",
        "delays_w_reasons['hour'] = pd.to_datetime(delays_w_reasons['time'], format='%H:%M').dt.hour\n",
        "\n",
        "# split and take first part\n",
        "delays_w_reasons['hour'] = delays_w_reasons['time'].str.split(':', expand=True)[0] #expandbool expands the split strings into separate columns\n",
        "delays_w_reasons['hour'] = delays_w_reasons['hour'].astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2578e3a",
      "metadata": {
        "id": "b2578e3a"
      },
      "source": [
        "## Filtering and selecting data\n",
        "\n",
        "Let's take another look at the TTC subway delay data. There are only 4 subway lines in Toronto, but `describe()` reported 17 unique values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8d26f1e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8d26f1e",
        "outputId": "640c4c2b-4092-4f50-b324-83d970628eaf"
      },
      "outputs": [],
      "source": [
        "delays_w_reasons['line'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37536ee5",
      "metadata": {
        "id": "37536ee5"
      },
      "source": [
        "Looks like some of the line values should be updated (YU/BD variants) and others should be dropped (e.g., 36 FINCH WEST, NaNs). Luckily there don't seem to be too many affected records, though the NaNs are not shown."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5449ef1f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5449ef1f",
        "outputId": "81c92614-ba62-42fa-e21f-ce291cf411e3"
      },
      "outputs": [],
      "source": [
        "delays_w_reasons['line'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ca268eb",
      "metadata": {
        "id": "4ca268eb"
      },
      "source": [
        "### `.loc[]` and `isna()`\n",
        "\n",
        "To find the records with no line, we can use `.loc[]`, which lets us access rows and columns with either a boolean array or row/column labels.\n",
        "\n",
        "In this case, the boolean array is the product of the `isna()` Series method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68732379",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "68732379",
        "outputId": "891f0c3d-dfc3-4ebf-ceb1-fd294dd08bf9"
      },
      "outputs": [],
      "source": [
        "# access rows of data where line is NA\n",
        "delays_w_reasons.loc[delays_w_reasons['line'].isna()]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e47dcb8a",
      "metadata": {
        "id": "e47dcb8a"
      },
      "source": [
        "`.loc[]` also lets us access data by label, with row conditions first and column conditions second."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "040456d6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "040456d6",
        "outputId": "d11f7547-2e3d-42f8-ee1d-95f4edc9f23f"
      },
      "outputs": [],
      "source": [
        "(delays_w_reasons.loc[delays_w_reasons['line'].isna(),  # filter rows\n",
        "                     ['time', 'station', 'line']]  # get columns\n",
        "                 .head())  # first 5 lines to save space"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91610b43",
      "metadata": {
        "id": "91610b43"
      },
      "source": [
        "### `query()`\n",
        "\n",
        "Alternatively, we can use the DataFrame `query()` method, which takes a filter condition as a string, and returns a DataFrame of records that met the condition. `query()` is slower than `loc[]`, but it can be easier to read."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OP1Qpdu7yEeN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OP1Qpdu7yEeN",
        "outputId": "22406659-4920-46ef-8fd0-3075f2b78593"
      },
      "outputs": [],
      "source": [
        "delays_w_reasons['line'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xqJlShnd0fBW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqJlShnd0fBW",
        "outputId": "f7a95c00-6390-41a6-88e1-453271dbf71f"
      },
      "outputs": [],
      "source": [
        "delays_w_reasons['line'].isna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35b5eb05",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "35b5eb05",
        "outputId": "e00dbc13-8cb4-4dbb-c1cd-463ec1898a25"
      },
      "outputs": [],
      "source": [
        "# slower than .loc, but can be easier to read\n",
        "delays_w_reasons.query('line.isna()').head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53f356d2",
      "metadata": {
        "id": "53f356d2"
      },
      "source": [
        "### `dropna()`\n",
        "\n",
        "In this case, the number of records without lines is relatively small. Most do not have delay durations. Some appear to be at rail yards, i.e. not on a rail line. For our analysis, we may drop them with the `dropna()` DataFrame method. We can drop rows missing lines by passing a `subset`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af8db773",
      "metadata": {
        "id": "af8db773"
      },
      "outputs": [],
      "source": [
        "delays_w_reasons = delays_w_reasons.dropna(subset=['line'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b0b4dab",
      "metadata": {
        "id": "3b0b4dab"
      },
      "source": [
        "### Filtering data with `.loc[]` and `isin()`\n",
        "\n",
        "We can use `.loc[]` to create a delays DataFrame without the invalid lines. To to this, we first create a list of values to exclude, then pass the list to the Series `isin()` method. Finally, we negate the expression, and assign the output back to `delays_w_reasons`.\n",
        "\n",
        "**Note: The negation operator here is `~`, not `!`. The `and` and `or` operators are different as well: `&` and `|` respectively.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6841bff3",
      "metadata": {
        "id": "6841bff3"
      },
      "outputs": [],
      "source": [
        "# set up filter list\n",
        "filter_list = ['999', '36 FINCH WEST', '35 JANE', '52', '41 KEELE']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0469986",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0469986",
        "outputId": "cd277477-4487-4d19-a13c-0e9579fbb56e"
      },
      "outputs": [],
      "source": [
        "# filter out records with invalid lines\n",
        "delays_w_reasons = delays_w_reasons.loc[~delays_w_reasons['line'].isin(filter_list)]\n",
        "delays_w_reasons['line'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5ae5e91",
      "metadata": {
        "id": "a5ae5e91"
      },
      "source": [
        "### Replacing values with `str.replace()`\n",
        "\n",
        "To standardize the YU/BD values, we can replace the less common ones. One way to do this is by selecting the line Series and using `str.replace()`, like below for \"YUS\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed6c34bc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed6c34bc",
        "outputId": "9501aad4-9d44-4bb5-8a27-9a86a120b922"
      },
      "outputs": [],
      "source": [
        "delays_w_reasons['line'] = (delays_w_reasons['line']\n",
        "                            .str.replace('YUS', 'YU'))\n",
        "delays_w_reasons['line'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca415f18",
      "metadata": {
        "id": "ca415f18"
      },
      "source": [
        "Another is to assign \"YU/BD\" to values selected by `.loc[]`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d478589f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d478589f",
        "outputId": "bbd5ff88-00b4-4d35-f644-1a9ec4837e95"
      },
      "outputs": [],
      "source": [
        "yubd_list = ['YONGE/UNIVERSITY/BLOOR',\n",
        "             'YU / BD',\n",
        "             'YU & BD',\n",
        "             'YU & BD LINES']\n",
        "\n",
        "# check the .loc[] selection\n",
        "delays_w_reasons.loc[delays_w_reasons['line'].isin(yubd_list), 'line']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c0d6d26",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c0d6d26",
        "outputId": "37e65274-668b-4243-8951-8987e97e5815"
      },
      "outputs": [],
      "source": [
        "delays_w_reasons.loc[delays_w_reasons['line'].isin(yubd_list), 'line'] = 'YU/BD'\n",
        "delays_w_reasons['line'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89c714a8",
      "metadata": {
        "id": "89c714a8"
      },
      "source": [
        "## Grouping\n",
        "\n",
        "A core workflow in `pandas` is _split-apply-combine_:\n",
        "* **splitting** data into groups\n",
        "* **applying** a function to each group, such as calculating group sums, standardizing data, or filtering out some groups\n",
        "* **combining** the results into a data structure"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "796c8a56",
      "metadata": {
        "id": "796c8a56"
      },
      "source": [
        "This workflow starts by grouping data by calling the `groupby()` method. We'll pass in a column name or list of names to group by."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75abe5b0",
      "metadata": {
        "id": "75abe5b0"
      },
      "outputs": [],
      "source": [
        "line_groups = delays_w_reasons.groupby('line')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "568b986a",
      "metadata": {
        "id": "568b986a"
      },
      "source": [
        "`groupby()` returns a grouped DataFrame that we can use to calculate groupwise statistics. The grouping column values become indexes, or row labels. **Note that this grouped DataFrame still references the original, so mutating one affects the other.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ba73a9f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ba73a9f",
        "outputId": "d0cec452-e0d7-4e9c-adc6-1e83c5a7d73e"
      },
      "outputs": [],
      "source": [
        "# how many hours of delays did each line have in 2021?\n",
        "line_groups['hour_delay'].sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44c2841b",
      "metadata": {
        "id": "44c2841b"
      },
      "source": [
        "We can group by more than one column by passing a list into `groupby()`. Data is grouped in the order of column names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e01fcae",
      "metadata": {
        "id": "7e01fcae"
      },
      "outputs": [],
      "source": [
        "# group by line first, then reason code description\n",
        "line_code_groups = delays_w_reasons.groupby(['line', 'code_description'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ByHPA-phqKO4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByHPA-phqKO4",
        "outputId": "a4b45cd3-da33-47a7-ba90-e42adcc25faa"
      },
      "outputs": [],
      "source": [
        "line_code_groups.size()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfe2015d",
      "metadata": {
        "id": "bfe2015d"
      },
      "source": [
        "### Chaining methods and `unstack()`ing\n",
        "\n",
        "We can _chain_ methods together for convenience and code readability. Here, we calculate the `size()` of each group, then `unstack()` the resulting Series by the first part of the row label, line. The `tail()` method is added to the end so that the output takes less screen space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65da4ee2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "65da4ee2",
        "outputId": "87045163-e228-4aeb-b60e-dc79587d5d6e"
      },
      "outputs": [],
      "source": [
        "# view the number of delays by reason and line\n",
        "line_code_groups.size().unstack(0).tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46476768",
      "metadata": {
        "id": "46476768"
      },
      "source": [
        "### `agg()`regating\n",
        "\n",
        "So far, we have applied one function at a time. The `agg()` DataFrame method lets us apply multiple functions on different columns at once.\n",
        "\n",
        "A key feature of agg() is that it can handle multiple aggregation operations at once, even different operations on different columns.\n",
        "\n",
        "`agg()`'s argument syntax is a little unusual. It follows this pattern:\n",
        "```python\n",
        "DataFrame.agg(agg_colname=('column_to_aggregate', 'aggregation_function_name'),\n",
        "              agg_colname2=('col_to_agg2', 'agg_func_name'))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d9c2e24",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "9d9c2e24",
        "outputId": "d0a4b3b0-af25-42c6-bac3-27b1602109f9"
      },
      "outputs": [],
      "source": [
        "delay_summary = (delays_w_reasons\n",
        "                 .groupby('date')\n",
        "                 .agg(delay_count=('station', 'count'),\n",
        "                      total_delay_min=('min_delay', 'sum'),\n",
        "                      mean_delay_min=('min_delay', 'mean')))\n",
        "\n",
        "delay_summary.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d231ace",
      "metadata": {
        "id": "3d231ace"
      },
      "source": [
        "## Plotting\n",
        "\n",
        "The summary table we just generated can be easily plotted within `pandas`. Since the index contains dates, `pandas` automatically knows to plot values as time series data, with the dates in the x-axis -- we just have to call the `plot()` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "305ef7e7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# If there are issues with library installation please type the following commands into Terminal:\n",
        "## conda install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdf7e9c6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "cdf7e9c6",
        "outputId": "5213e8ca-e074-4650-c34e-178a959d27bd"
      },
      "outputs": [],
      "source": [
        "delay_summary.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3642c2b3",
      "metadata": {
        "id": "3642c2b3"
      },
      "source": [
        "To create a separate plot for each column, we can specify `subplots=True`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8eb53896",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "id": "8eb53896",
        "outputId": "784aeca2-e926-4009-f7c5-df06b207efc1"
      },
      "outputs": [],
      "source": [
        "delay_summary.plot(subplots=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2a69b4f",
      "metadata": {
        "id": "a2a69b4f"
      },
      "source": [
        "We can plot other aggregations too. Below, we use `line_groups` and calculate the size of each group, i.e., the number of delays reported on each line. Then we plot the data, telling `pandas` that the plot `kind` should be a bar graph, with TTC lines should in the `x`-axis. We also pass in a title."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "669a85d3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "id": "669a85d3",
        "outputId": "54757256-ef2a-4c9c-c6d5-f1a853c6ad97"
      },
      "outputs": [],
      "source": [
        "(line_groups\n",
        " .size()\n",
        " .plot(x='line',\n",
        "       kind='bar',\n",
        "       title='Delays by Subway Line, 2021'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f62e572",
      "metadata": {
        "id": "8f62e572"
      },
      "source": [
        "It is possible to sum up and plot the total delay time, in hours, by line."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b47be79",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "7b47be79",
        "outputId": "836964a0-5fbf-464a-a063-505a8b891267"
      },
      "outputs": [],
      "source": [
        "(delays_w_reasons\n",
        " .groupby('line')['min_delay']\n",
        " .sum()\n",
        " .plot(x='line', kind='bar'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab74a77e",
      "metadata": {
        "id": "ab74a77e"
      },
      "source": [
        "# Writing to file"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7979702c",
      "metadata": {
        "id": "7979702c"
      },
      "source": [
        "## Exporting DataFrames\n",
        "\n",
        "DataFrames have `to_[file format]()` methods, analagous to `pandas` read functions. The counterpart to `pd.read_csv()`, for instance, is `DataFrame.to_csv()`. The export methods generally take a file path to save to as their first argument. Additional arguments vary a bit by export format, but `index` is a common useful one. It takes a boolean of whether to write the index to file -- set it to `False` if the index is the numbered default.\n",
        "\n",
        "Two additional useful parameters in `DataFrame.to_csv()` and `DataFrame.to_excel()` are `na_rep`, which takes a string to use for null values, and `columns`, which lets us write out a subset of columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91f7c8f3",
      "metadata": {
        "id": "91f7c8f3"
      },
      "outputs": [],
      "source": [
        "# write delays_w_reasons to an Excel file\n",
        "delays_w_reasons.to_excel('../../05_src/data/slides_data/ttc_subway_delays_w_reasons.xlsx', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d1c483c",
      "metadata": {
        "id": "0d1c483c"
      },
      "source": [
        "# References"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f0d2c99",
      "metadata": {
        "id": "9f0d2c99"
      },
      "source": [
        "### Programming\n",
        "- pandas development team. _API reference_. https://pandas.pydata.org/pandas-docs/stable/reference/index.html\n",
        "- pandas development team. _User guide_. https://pandas.pydata.org/pandas-docs/stable/user_guide/index.html\n",
        "- _Python strftime cheatsheet_. https://strftime.org/\n",
        "\n",
        "\n",
        "### Data Sources\n",
        "- Open Data Toronto. _Neighbourhood Profiles_. https://open.toronto.ca/dataset/neighbourhood-profiles/\n",
        "- Open Data Toronto. _TTC Subway Delay Data_. https://open.toronto.ca/dataset/ttc-subway-delay-data/\n",
        "- Open Data Toronto. _Bicyle Thefts_. https://open.toronto.ca/dataset/bicycle-thefts/"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "colab": {
      "collapsed_sections": [
        "4339b9f2",
        "72e9148c",
        "9f0d2c99"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "rise": {
      "scroll": true,
      "theme": "solarized",
      "transition": "none"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
